{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(37, 131, 207);\">Fractured or not-fractured that is the question</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses **computer vision** to help identify fractured-bones in X-ray images. It's a binary classification problem using deep learing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">Objective</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To acquire X-ray images of fractured and healthy bones to train the CNN.\n",
    "- Split the dataset into train, test and validation.\n",
    "- Train a simple CNN.\n",
    "- Predict the outcome.\n",
    "- Calculate the accuracy.\n",
    "- Fine tune the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">Import all the libraries here</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">Check Tensorflow compilation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Is GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "print(\"CUDA support:\", tf_build_info.build_info.get(\"cuda_version\", \"Not built with CUDA\"))\n",
    "print(\"cuDNN support:\", tf_build_info.build_info.get(\"cudnn_version\", \"Not built with cuDNN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compiled with CUDA:\", tf.sysconfig.get_build_info()[\"cuda_version\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tensorflow is compiled with CUDA. So it has GPU support and CNN training would be fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">Data extraction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd().replace(\"code\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the dataset path and structure\n",
    "print(\"Dataset path:\", data_path)\n",
    "print(\"Contents of dataset_path:\", os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(data_path, \"train\")\n",
    "test_dir = os.path.join(data_path, \"test\")\n",
    "validation_dir = os.path.join(data_path, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify train, test and validation directories\n",
    "print(\"Train directory contents:\", os.listdir(train_dir))\n",
    "print(\"Test directory contents:\", os.listdir(test_dir))\n",
    "print(\"Validation directory contents:\", os.listdir(validation_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:rgb(37, 131, 207);\">Remove spaces and rename files</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files_recursive(folder_path):\n",
    "    \"\"\"\n",
    "    Recursively renames files in the given folder and its subfolders,\n",
    "    replacing spaces with underscores in filenames.\n",
    "    \"\"\"\n",
    "    for dirpath, _, filenames in os.walk(folder_path):\n",
    "        for filename in filenames:\n",
    "            if ' ' in filename:\n",
    "                old_path = os.path.join(dirpath, filename)\n",
    "                new_filename = filename.replace(' ', '_')\n",
    "                new_path = os.path.join(dirpath, new_filename)\n",
    "                os.rename(old_path, new_path)\n",
    "                print(f'Renamed: \"{old_path}\" â†’ \"{new_path}\"')\n",
    "\n",
    "rename_files_recursive(os.path.join(train_dir, \"fractured\"))\n",
    "rename_files_recursive(os.path.join(train_dir, \"not fractured\"))\n",
    "rename_files_recursive(os.path.join(test_dir, \"fractured\"))\n",
    "rename_files_recursive(os.path.join(test_dir, \"not fractured\"))\n",
    "rename_files_recursive(os.path.join(validation_dir, \"fractured\"))\n",
    "rename_files_recursive(os.path.join(validation_dir, \"not fractured\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:rgb(37, 131, 207);\">Remove corrupted images using tf.io.read_file()</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_images(folder_path):\n",
    "    removed = 0\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for fname in files:\n",
    "            fpath = os.path.join(root, fname)\n",
    "            try:\n",
    "                img_read = tf.io.read_file(fpath)\n",
    "                img_2 = tf.image.decode_image(img_read)\n",
    "            \n",
    "            except tf.errors.InvalidArgumentError:\n",
    "                print(f\"Removing: {fpath}\")\n",
    "                os.remove(fpath)\n",
    "                removed += 1\n",
    "    print(f\"Removed {removed} corrupted/invalid images from {folder_path}\")\n",
    "\n",
    "# Check all your datasets\n",
    "remove_invalid_images(os.path.join(train_dir, \"fractured\"))\n",
    "remove_invalid_images(os.path.join(train_dir, \"not fractured\"))\n",
    "remove_invalid_images(os.path.join(test_dir, \"fractured\"))\n",
    "remove_invalid_images(os.path.join(test_dir, \"not fractured\"))\n",
    "remove_invalid_images(os.path.join(validation_dir, \"fractured\"))\n",
    "remove_invalid_images(os.path.join(validation_dir, \"not fractured\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">Creating TensorFlow data object & visualizing the dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size\n",
    "batch_size = 32\n",
    "\n",
    "# image_size\n",
    "img_size = (160, 160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">Train-test split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir, shuffle=True, batch_size=batch_size, image_size=img_size, labels='inferred')\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(test_dir, shuffle=True, batch_size=batch_size, image_size=img_size, labels='inferred')\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir, shuffle=True, batch_size=batch_size, image_size=img_size, labels='inferred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling images from training dataset\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(2):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.suptitle(\"Sample Images from Training Dataset\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling images from testing dataset\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in test_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.suptitle(\"Sample Images from Testing Dataset\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling images from validation dataset\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in validation_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.suptitle(\"Sample Images from Validation Dataset\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">Prefetching for optimization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotune = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize dataset performance with prefetching\n",
    "train_dataset = train_dataset.prefetch(buffer_size=autotune)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=autotune)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">Data Augmentation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "horizontal_flips = tf.keras.layers.RandomFlip('horizontal')\n",
    "radians = tf.keras.layers.RandomRotation(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    horizontal_flips,\n",
    "    radians\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmented images\n",
    "plt.figure(figsize=(12, 12))\n",
    "for images, _ in train_dataset.take(1):\n",
    "    sample_image = images[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(tf.expand_dims(sample_image, 0))\n",
    "        plt.imshow(augmented_image[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Augmented Image {i+1}\", fontsize=12)\n",
    "plt.suptitle(\"Sample Augmented Images\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">Transfer learning with MobileNetV2</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = img_size + (3,) # MobileNetV2 only works with RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">CNN Architechture</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=img_shape, \n",
    "                                               include_top=False, # Exclude the ImageNet classifier at the top\n",
    "                                               weights='imagenet') # Use the pre-trained weights from ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False # Freeze the base model to keep the pre-trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=img_shape)\n",
    "x = data_augmentation(inputs)\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "x = base_model(x, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D() # layer object\n",
    "\n",
    "# Apply the layer to MobileNetV2\n",
    "x = global_average_layer(x)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x) ### Optional: Add a dropout layer\n",
    "\n",
    "prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid') # layer object\n",
    "# Apply Fully Connected Layer to predict the class\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of neurons:\", prediction_layer.units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">Training the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.1,\n",
    "    decay_steps=batch_size, # Learning rate will decrease every batch\n",
    "    decay_rate=0.8 # rate of decrease means 90% of the learning rate is decreased\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model structure for training\n",
    "base_learning_rate = 0.1\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), # Adam deals with gradient descent\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(), # measures the difference between two probability distributions\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')]) # calculates how often predictions match binary labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">Early stop, epochs & saving the best model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(filepath='best_model.keras', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs are the number of times the model will see the entire dataset\n",
    "# Start with a small number of epochs to prevent overfitting\n",
    "# Epochs usually are in the range of 10 to 100. Standard is up to 50.\n",
    "initial_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">Training & saving (best model + metrics)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start time\n",
    "start = time.time()\n",
    "\n",
    "import json\n",
    "\n",
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=initial_epochs,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=[early_stopping, model_checkpoint], # Callbacks are used to customize the training process\n",
    "    verbose=2  # Verbosity level: 1 = progress bar, 2 = one line per epoch\n",
    ")\n",
    "\n",
    "# Save training history\n",
    "with open('training_history.json', 'w') as file: # open creates a file\n",
    "    json.dump(history.history, file) # dump saves it as a json file\n",
    "\n",
    "# end time\n",
    "end = time.time()\n",
    "print(f\"Elapsed time: {end - start:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(37, 131, 207);\">Evaluating the basic model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the best of the basic models\n",
    "model_basic = tf.keras.models.load_model('best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the basic model on the test dataset\n",
    "test_loss_basic, test_accuracy_basic = model_basic.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training history\n",
    "with open('training_history.json', 'r') as file:\n",
    "    training_history = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history[\"val_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "#settings\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "epochs = np.arange(len(training_history[\"accuracy\"]))\n",
    "fs = 14\n",
    "fs_ticks = 10\n",
    "# training and validation accuracy\n",
    "ax[0].plot(epochs, training_history[\"accuracy\"], label=\"Training accuracy\")\n",
    "ax[0].plot(epochs, training_history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
    "ax[0].set_ylabel(\"Accuracy\", fontsize=fs)\n",
    "ax[0].grid(True, alpha=0.5)\n",
    "ax[0].set_xlabel(\"Epochs\", fontsize=fs)\n",
    "ax[0].legend(frameon=False, fontsize=fs)\n",
    "\n",
    "# trainng and validation loss\n",
    "ax[1].plot(epochs, training_history[\"loss\"], label=\"Training loss\")\n",
    "ax[1].plot(epochs, training_history[\"val_loss\"], label=\"Validation loss\")\n",
    "ax[1].set_ylabel(\"Loss\", fontsize=fs)\n",
    "ax[1].grid(True, alpha=0.5)\n",
    "ax[1].set_xlabel(\"Epochs\", fontsize=fs)\n",
    "ax[1].legend(frameon=False, fontsize=fs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../plot/accuracy_loss_basic.png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_basic = []\n",
    "y_pred_basic = []\n",
    "\n",
    "for X_batch_basic, labels in test_dataset:\n",
    "    preds = model_basic.predict(X_batch_basic).flatten()\n",
    "    bin_preds = (preds > 0.5).astype(\"int32\")\n",
    "    y_true_basic.extend(labels.numpy())\n",
    "    y_pred_basic.extend(bin_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground_truth is your y_true\n",
    "#prediction is your y_pred\n",
    "ground_truth_basic = y_true_basic\n",
    "predictions_basic = y_pred_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion a\n",
    "conf_matrix = confusion_matrix(ground_truth_basic, predictions_basic)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"../plot/cm_basic.png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(ground_truth_basic, predictions_basic, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test data\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "\n",
    "# Generate predictions\n",
    "predictions_basic = model_basic.predict_on_batch(image_batch).flatten()\n",
    "predictions_basic = tf.where(predictions_basic < 0.5, 0, 1).numpy()  # Apply threshold for binary classification\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(16, 6))\n",
    "for i in range(16):  # Increase the number of images to 16\n",
    "    ax = plt.subplot(2, 8, i + 1)  # Adjust the grid to 4x4\n",
    "    plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "    true_label = label_batch[i]\n",
    "    pred_label = predictions_basic[i]\n",
    "    title = f\"True: {class_names[true_label]}\\nPred: {class_names[pred_label]}\"\n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    plt.title(title, color=color, fontsize=14)  # Make the font size smaller\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Predictions on Test Data\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "#plt.subplots_adjust(top=0.92)\n",
    "plt.savefig(\"../plot/predictions_basic_2.png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
