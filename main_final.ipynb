{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6fd2f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Bone Fracture Detection using Deep Learning (CNN)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# This project uses deep learning and computer vision to classify bone fractures from X-ray images.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Bone Fracture Detection using Deep Learning (CNN)\n",
    "# This project uses deep learning and computer vision to classify bone fractures from X-ray images.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Display TensorFlow version and GPU availability\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"GPU Availability:\", tf.config.list_physical_devices('GPU'))\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "print(\"CUDA Support:\", tf_build_info.build_info.get(\"cuda_version\", \"Not compiled with CUDA\"))\n",
    "print(\"cuDNN Support:\", tf_build_info.build_info.get(\"cudnn_version\", \"Not compiled with cuDNN\"))\n",
    "\n",
    "# Set up paths for dataset\n",
    "project_dir = os.getcwd().replace(\"code\", \"dataset\")\n",
    "print(f\"Dataset Directory: {project_dir}\")\n",
    "train_dir = os.path.join(project_dir, \"train\")\n",
    "test_dir = os.path.join(project_dir, \"test\")\n",
    "val_dir = os.path.join(project_dir, \"val\")\n",
    "\n",
    "# Verify dataset contents\n",
    "print(\"Training Directory Contents:\", os.listdir(train_dir))\n",
    "print(\"Test Directory Contents:\", os.listdir(test_dir))\n",
    "print(\"Validation Directory Contents:\", os.listdir(val_dir))\n",
    "\n",
    "# Function to rename files, replacing spaces with underscores\n",
    "def rename_files_in_directory(directory):\n",
    "    \"\"\"\n",
    "    Rename files by replacing spaces with underscores in the directory and subdirectories.\n",
    "    \"\"\"\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if ' ' in file:\n",
    "                old_path = os.path.join(root, file)\n",
    "                new_file = file.replace(' ', '_')\n",
    "                new_path = os.path.join(root, new_file)\n",
    "                os.rename(old_path, new_path)\n",
    "                print(f'Renamed: \"{old_path}\" â†’ \"{new_path}\"')\n",
    "\n",
    "# Rename files in train, test, and validation directories\n",
    "rename_files_in_directory(os.path.join(train_dir, \"fractured\"))\n",
    "rename_files_in_directory(os.path.join(train_dir, \"not_fractured\"))\n",
    "rename_files_in_directory(os.path.join(test_dir, \"fractured\"))\n",
    "rename_files_in_directory(os.path.join(test_dir, \"not_fractured\"))\n",
    "rename_files_in_directory(os.path.join(val_dir, \"fractured\"))\n",
    "rename_files_in_directory(os.path.join(val_dir, \"not_fractured\"))\n",
    "\n",
    "# Function to remove invalid or corrupted images\n",
    "def clean_invalid_images(directory):\n",
    "    invalid_count = 0\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                img = tf.io.read_file(file_path)\n",
    "                tf.image.decode_image(img)  # Try decoding the image\n",
    "            except tf.errors.InvalidArgumentError:\n",
    "                print(f\"Invalid Image Removed: {file_path}\")\n",
    "                os.remove(file_path)\n",
    "                invalid_count += 1\n",
    "    print(f\"Removed {invalid_count} invalid images from {directory}\")\n",
    "\n",
    "# Clean invalid images from all directories\n",
    "clean_invalid_images(os.path.join(train_dir, \"fractured\"))\n",
    "clean_invalid_images(os.path.join(train_dir, \"not_fractured\"))\n",
    "clean_invalid_images(os.path.join(test_dir, \"fractured\"))\n",
    "clean_invalid_images(os.path.join(test_dir, \"not_fractured\"))\n",
    "clean_invalid_images(os.path.join(val_dir, \"fractured\"))\n",
    "clean_invalid_images(os.path.join(val_dir, \"not_fractured\"))\n",
    "\n",
    "# Set batch size and image size\n",
    "batch_size = 32\n",
    "image_dimensions = (160, 160)\n",
    "\n",
    "# Create datasets from directories\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(train_dir, shuffle=True, batch_size=batch_size, image_size=image_dimensions)\n",
    "test_data = tf.keras.utils.image_dataset_from_directory(test_dir, shuffle=True, batch_size=batch_size, image_size=image_dimensions)\n",
    "val_data = tf.keras.utils.image_dataset_from_directory(val_dir, shuffle=True, batch_size=batch_size, image_size=image_dimensions)\n",
    "\n",
    "# Class names (fractured vs not fractured)\n",
    "class_names = train_data.class_names\n",
    "print(\"Class Names:\", class_names)\n",
    "\n",
    "# Visualizing some sample images from the training set\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_data.take(2):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.suptitle(\"Training Dataset Samples\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n",
    "\n",
    "# Prefetch the datasets for optimization\n",
    "train_data = train_data.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_data = val_data.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_data = test_data.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Image Augmentation\n",
    "aug_flip = tf.keras.layers.RandomFlip('horizontal')\n",
    "aug_rotate = tf.keras.layers.RandomRotation(0.02)\n",
    "augmentation_pipeline = tf.keras.Sequential([aug_flip, aug_rotate])\n",
    "\n",
    "# Display some augmented images\n",
    "plt.figure(figsize=(12, 12))\n",
    "for images, _ in train_data.take(1):\n",
    "    sample_image = images[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_img = augmentation_pipeline(tf.expand_dims(sample_image, 0))\n",
    "        plt.imshow(augmented_img[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Augmented Image {i+1}\", fontsize=12)\n",
    "plt.suptitle(\"Sample Augmented Images\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n",
    "\n",
    "# Transfer Learning with MobileNetV2\n",
    "input_shape = image_dimensions + (3,)  # RGB images\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "# Building the final model\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "x = augmentation_pipeline(inputs)\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)  # Optional dropout layer for regularization\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "learning_rate_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.1, decay_steps=batch_size, decay_rate=0.8)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping and model checkpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Training the model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_data, epochs=20, validation_data=val_data, callbacks=[early_stopping_callback, model_checkpoint_callback], verbose=2)\n",
    "\n",
    "# Save the training history\n",
    "with open('training_history.json', 'w') as file:\n",
    "    json.dump(history.history, file)\n",
    "\n",
    "# Evaluate the model\n",
    "model = tf.keras.models.load_model('best_model.h5')\n",
    "test_loss, test_acc = model.evaluate(test_data)\n",
    "\n",
    "# Plot training and validation accuracy & loss\n",
    "with open('training_history.json', 'r') as file:\n",
    "    history_data = json.load(file)\n",
    "\n",
    "epochs_range = np.arange(len(history_data['accuracy']))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot accuracy\n",
    "ax[0].plot(epochs_range, history_data['accuracy'], label='Training Accuracy')\n",
    "ax[0].plot(epochs_range, history_data['val_accuracy'], label='Validation Accuracy')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].legend()\n",
    "\n",
    "# Plot loss\n",
    "ax[1].plot(epochs_range, history_data['loss'], label='Training Loss')\n",
    "ax[1].plot(epochs_range, history_data['val_loss'], label='Validation Loss')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# End of script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4484969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLFLOW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
